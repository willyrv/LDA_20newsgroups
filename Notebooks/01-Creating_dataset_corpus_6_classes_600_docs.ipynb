{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the distance matrix\n",
    "\n",
    "In this notebook we do the following:\n",
    "* Take a dictionary **D1** of words with gensim, using the 20 newsgroups corpus as input dataset\n",
    "* Create a gensim representation of the 20newsgroups corpus based on this new dictionary \n",
    "* Save the results using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_number = 2\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, clean up the 20 Newsgroups dataset. We will use it to fit LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the following 6 groups:\n",
    "* comp.graphics (1)\n",
    "* comp.os.ms-windows.misc (2)\n",
    "* rec.autos (7)\n",
    "* rec.motorcycles (8)\n",
    "* sci.med (13)\n",
    "* sci.space (14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_to_keep = [1, 2, 7, 8, 13, 14]\n",
    "nb_of_documents_class = 100\n",
    "newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'sci.med',\n",
       " 'sci.space']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[newsgroups.target_names[t] for t in targets_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"text\":newsgroups.data, \"target\": newsgroups.target})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_6classes = data[data[\"target\"].isin(targets_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3554, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_6classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     598\n",
       "7     594\n",
       "13    594\n",
       "14    593\n",
       "2     591\n",
       "1     584\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_6classes.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 100 documents from each class\n",
    "corpus_6classes_600docs = corpus_6classes.groupby(\"target\").head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14\n",
       "6  From: bmdelane@quads.uchicago.edu (brian manni...      13\n",
       "8  From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...       2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_6classes_600docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-05 15:36:26,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-06-05 15:36:26,653 : INFO : built Dictionary(28969 unique tokens: ['60s', '70s', 'addition', 'anyone', 'body']...) from 600 documents (total 108075 corpus positions)\n",
      "2021-06-05 15:36:26,710 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(28969 unique tokens: ['60s', '70s', 'addition', 'anyone', 'body']...) from 600 documents (total 108075 corpus positions)\", 'datetime': '2021-06-05T15:36:26.654238', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-5.8.0-53-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2021-06-05 15:36:26,768 : INFO : discarding 26488 tokens: [('60s', 3), ('70s', 4), ('bricklin', 2), ('edu', 368), ('enlighten', 4), ('funky', 4), ('host', 268), ('lerxst', 2), ('lines', 597), ('neighborhood', 4)]...\n",
      "2021-06-05 15:36:26,769 : INFO : keeping 2481 tokens which were in no less than 5 and no more than 180 (=30.0%) documents\n",
      "2021-06-05 15:36:26,795 : INFO : resulting dictionary: Dictionary(2481 unique tokens: ['addition', 'anyone', 'body', 'brought', 'bumper']...)\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "stemmer = PorterStemmer()\n",
    "translate_tab = {ord(p): u\" \" for p in punctuation}\n",
    "\n",
    "def text2tokens(raw_text):\n",
    "    \"\"\"Split the raw_text string into a list of stemmed tokens.\"\"\"\n",
    "    clean_text = raw_text.lower().translate(translate_tab)\n",
    "    tokens = [token.strip() for token in tokenizer.tokenize(clean_text)]\n",
    "    tokens = [token for token in tokens if token not in eng_stopwords]\n",
    "    # stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # return [token for token in stemmed_tokens if len(token) > 2]  # skip short tokens\n",
    "    return [token for token in tokens if len(token) > 2]  # skip short tokens\n",
    "\n",
    "dataset = [text2tokens(txt) for txt in list(corpus_6classes_600docs['text'].values)]  # convert a documents to list of tokens\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(documents=dataset, prune_at=None)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.3, keep_n=None)  # use Dictionary to remove un-relevant tokens\n",
    "dictionary.compactify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2b_dataset = [dictionary.doc2bow(doc) for doc in dataset]  # convert list of tokens to bag of word representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the corpus and the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the corpus representation in gensim format\n",
    "# and the corresponding dictionary\n",
    "with open(\"./20newsgroup_corpus_gensim_6classes_600docs.pickle\", 'wb') as f:\n",
    "    pickle.dump(d2b_dataset, f)\n",
    "\n",
    "with open(\"./dictionary_20newsgroups_6classes_600docs.pickle\", 'wb') as f:\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_6classes_600docs.to_csv(\"./20newsgroup_corpus_6classes_600docs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
